{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Admin_server\n",
      "[nltk_data]     APN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('genesis')\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', 'need')\n",
      "('need', 'to')\n",
      "('to', 'write')\n",
      "('write', 'a')\n",
      "('a', 'program')\n",
      "('program', 'in')\n",
      "('in', 'NLTK')\n",
      "('NLTK', 'that')\n",
      "('that', 'breaks')\n",
      "('breaks', 'a')\n",
      "('a', 'corpus')\n",
      "('corpus', '(')\n",
      "('(', 'a')\n",
      "('a', 'large')\n",
      "('large', 'collection')\n",
      "('collection', 'of')\n",
      "('of', 'txt')\n",
      "('txt', 'files')\n",
      "('files', ')')\n",
      "(')', 'into')\n",
      "('into', 'unigrams')\n",
      "('unigrams', ',')\n",
      "(',', 'bigrams')\n",
      "('bigrams', ',')\n",
      "(',', 'trigrams')\n",
      "('trigrams', ',')\n",
      "(',', 'fourgrams')\n",
      "('fourgrams', 'and')\n",
      "('and', 'fivegrams')\n",
      "('fivegrams', '.')\n",
      "('.', 'I')\n",
      "('I', 'need')\n",
      "('need', 'to')\n",
      "('to', 'write')\n",
      "('write', 'a')\n",
      "('a', 'program')\n",
      "('program', 'in')\n",
      "('in', 'NLTK')\n",
      "('NLTK', 'that')\n",
      "('that', 'breaks')\n",
      "('breaks', 'a')\n",
      "('a', 'corpus')\n"
     ]
    }
   ],
   "source": [
    "#An n-gram is a contiguous sequence of n items from a given sequence of text or speech. \n",
    "#The items can be syllables, letters, words or base pairs according to the application. \n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "text = \"I need to write a program in NLTK that breaks a corpus (a large collection of txt files) into unigrams, bigrams, trigrams, fourgrams and fivegrams. I need to write a program in NLTK that breaks a corpus\"\n",
    "token = nltk.word_tokenize(text)\n",
    "bigrams = ngrams(token,2)\n",
    "for grams in bigrams:print(grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', 'need', 'to')\n",
      "('need', 'to', 'write')\n",
      "('to', 'write', 'a')\n",
      "('write', 'a', 'program')\n",
      "('a', 'program', 'in')\n",
      "('program', 'in', 'NLTK')\n",
      "('in', 'NLTK', 'that')\n",
      "('NLTK', 'that', 'breaks')\n",
      "('that', 'breaks', 'a')\n",
      "('breaks', 'a', 'corpus')\n",
      "('a', 'corpus', '(')\n",
      "('corpus', '(', 'a')\n",
      "('(', 'a', 'large')\n",
      "('a', 'large', 'collection')\n",
      "('large', 'collection', 'of')\n",
      "('collection', 'of', 'txt')\n",
      "('of', 'txt', 'files')\n",
      "('txt', 'files', ')')\n",
      "('files', ')', 'into')\n",
      "(')', 'into', 'unigrams')\n",
      "('into', 'unigrams', ',')\n",
      "('unigrams', ',', 'bigrams')\n",
      "(',', 'bigrams', ',')\n",
      "('bigrams', ',', 'trigrams')\n",
      "(',', 'trigrams', ',')\n",
      "('trigrams', ',', 'fourgrams')\n",
      "(',', 'fourgrams', 'and')\n",
      "('fourgrams', 'and', 'fivegrams')\n",
      "('and', 'fivegrams', '.')\n",
      "('fivegrams', '.', 'I')\n",
      "('.', 'I', 'need')\n",
      "('I', 'need', 'to')\n",
      "('need', 'to', 'write')\n",
      "('to', 'write', 'a')\n",
      "('write', 'a', 'program')\n",
      "('a', 'program', 'in')\n",
      "('program', 'in', 'NLTK')\n",
      "('in', 'NLTK', 'that')\n",
      "('NLTK', 'that', 'breaks')\n",
      "('that', 'breaks', 'a')\n",
      "('breaks', 'a', 'corpus')\n"
     ]
    }
   ],
   "source": [
    "trigrams = ngrams(token,3)\n",
    "for grams in trigrams:print(grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', 'need') 2\n",
      "('need', 'to') 2\n",
      "('to', 'write') 2\n",
      "('write', 'a') 2\n",
      "('a', 'program') 2\n",
      "('program', 'in') 2\n",
      "('in', 'NLTK') 2\n",
      "('NLTK', 'that') 2\n",
      "('that', 'breaks') 2\n",
      "('breaks', 'a') 2\n",
      "('a', 'corpus') 2\n",
      "('corpus', '(') 1\n",
      "('(', 'a') 1\n",
      "('a', 'large') 1\n",
      "('large', 'collection') 1\n",
      "('collection', 'of') 1\n",
      "('of', 'txt') 1\n",
      "('txt', 'files') 1\n",
      "('files', ')') 1\n",
      "(')', 'into') 1\n",
      "('into', 'unigrams') 1\n",
      "('unigrams', ',') 1\n",
      "(',', 'bigrams') 1\n",
      "('bigrams', ',') 1\n",
      "(',', 'trigrams') 1\n",
      "('trigrams', ',') 1\n",
      "(',', 'fourgrams') 1\n",
      "('fourgrams', 'and') 1\n",
      "('and', 'fivegrams') 1\n",
      "('fivegrams', '.') 1\n",
      "('.', 'I') 1\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "temp=nltk.collocations.BigramCollocationFinder.from_words(token)\n",
    "for bigram, freq in temp.ngram_fd.items():\n",
    "     print(bigram, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', 'need', 'to', 'write') 2\n",
      "('need', 'to', 'write', 'a') 2\n",
      "('to', 'write', 'a', 'program') 2\n",
      "('write', 'a', 'program', 'in') 2\n",
      "('a', 'program', 'in', 'NLTK') 2\n",
      "('program', 'in', 'NLTK', 'that') 2\n",
      "('in', 'NLTK', 'that', 'breaks') 2\n",
      "('NLTK', 'that', 'breaks', 'a') 2\n",
      "('that', 'breaks', 'a', 'corpus') 2\n",
      "('breaks', 'a', 'corpus', '(') 1\n",
      "('a', 'corpus', '(', 'a') 1\n",
      "('corpus', '(', 'a', 'large') 1\n",
      "('(', 'a', 'large', 'collection') 1\n",
      "('a', 'large', 'collection', 'of') 1\n",
      "('large', 'collection', 'of', 'txt') 1\n",
      "('collection', 'of', 'txt', 'files') 1\n",
      "('of', 'txt', 'files', ')') 1\n",
      "('txt', 'files', ')', 'into') 1\n",
      "('files', ')', 'into', 'unigrams') 1\n",
      "(')', 'into', 'unigrams', ',') 1\n",
      "('into', 'unigrams', ',', 'bigrams') 1\n",
      "('unigrams', ',', 'bigrams', ',') 1\n",
      "(',', 'bigrams', ',', 'trigrams') 1\n",
      "('bigrams', ',', 'trigrams', ',') 1\n",
      "(',', 'trigrams', ',', 'fourgrams') 1\n",
      "('trigrams', ',', 'fourgrams', 'and') 1\n",
      "(',', 'fourgrams', 'and', 'fivegrams') 1\n",
      "('fourgrams', 'and', 'fivegrams', '.') 1\n",
      "('and', 'fivegrams', '.', 'I') 1\n",
      "('fivegrams', '.', 'I', 'need') 1\n",
      "('.', 'I', 'need', 'to') 1\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "tokens = nltk.wordpunct_tokenize(text)\n",
    "temp=nltk.collocations.QuadgramCollocationFinder.from_words(token)\n",
    "for fourgram, freq in temp.ngram_fd.items():  \n",
    "    print(fourgram, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Allon', 'Bacuth'),\n",
       " ('Ashteroth', 'Karnaim'),\n",
       " ('Ben', 'Ammi'),\n",
       " ('En', 'Mishpat'),\n",
       " ('Jegar', 'Sahadutha'),\n",
       " ('Salt', 'Sea'),\n",
       " ('Whoever', 'sheds'),\n",
       " ('appoint', 'overseers'),\n",
       " ('aromatic', 'resin'),\n",
       " ('cutting', 'instrument')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us use Bigram Association measures which scores collocations or other associations\n",
    "#(nlp.stanford.edu/fsnlp/promo/colloc.pdf)\n",
    "#Example: pmi, likelihood_ratio, student_t,chi_sq,\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "#Collect the bigram statistics from the corpus\n",
    "finder = BigramCollocationFinder.from_words(nltk.corpus.genesis.words('english-web.txt'))\n",
    "#find the top 10 bigrams from the corpus\n",
    "finder.nbest(bigram_measures.pmi, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('1,119', 'UNK'), ('votes', 'UNK')),\n",
       " (('1962', 'UNK'), (\"governor's\", 'UNK')),\n",
       " (('637', 'UNK'), ('E.', 'UNK')),\n",
       " (('Alpharetta', 'UNK'), ('prison', 'UNK')),\n",
       " (('Bar', 'UNK'), ('Association', 'UNK'))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find collocations among tagged words using pmi:\n",
    "finder = BigramCollocationFinder.from_words(nltk.corpus.brown.tagged_words('ca01', tagset='upenn_tagset'))\n",
    "finder.nbest(bigram_measures.pmi, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'urged', 'that', 'the', 'city', '``', 'take', 'steps', 'to', 'remedy', \"''\", 'this', 'problem', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "test_sent = brown.sents(categories='news')[10]\n",
    "print(test_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'PPS'), ('urged', 'VBD'), ('that', 'CS'), ('the', 'AT'), ('city', 'NN'), ('``', '``'), ('take', 'VB'), ('steps', 'NNS'), ('to', 'TO'), ('remedy', 'VB'), (\"''\", \"''\"), ('this', 'DT'), ('problem', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "test_sent = brown.tagged_sents(categories='news')[10]\n",
    "print(test_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('.', '.'), ('The', 'DET')),\n",
       " ((\"''\", '.'), ('.', '.')),\n",
       " (('in', 'ADP'), ('the', 'DET')),\n",
       " ((',', '.'), ('the', 'DET')),\n",
       " (('of', 'ADP'), ('the', 'DET'))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find collocations among tagged words using student_t measure :\n",
    "finder = BigramCollocationFinder.from_words(nltk.corpus.brown.tagged_words('ca01', tagset='universal'))\n",
    "finder.nbest(bigram_measures.student_t, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('.', '.'), ('The', 'DET')),\n",
       " ((\"''\", '.'), ('.', '.')),\n",
       " (('Fulton', 'NOUN'), ('County', 'NOUN')),\n",
       " (('Highway', 'NOUN'), ('Department', 'NOUN')),\n",
       " (('jury', 'NOUN'), ('said', 'VERB'))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find collocations among tagged words using likelihood_ratio measure :\n",
    "finder = BigramCollocationFinder.from_words(nltk.corpus.brown.tagged_words('ca01', tagset='universal'))\n",
    "finder.nbest(bigram_measures.likelihood_ratio, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PRT', 'VERB'),\n",
       " ('PRON', 'VERB'),\n",
       " ('ADP', 'DET'),\n",
       " ('.', 'PRON'),\n",
       " ('DET', 'ADJ'),\n",
       " ('CONJ', 'PRON'),\n",
       " ('ADP', 'NUM'),\n",
       " ('NUM', '.'),\n",
       " ('ADV', 'ADV'),\n",
       " ('VERB', 'ADV')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find collocations of tags:\n",
    "finder = BigramCollocationFinder.from_words(t for w, t in nltk.corpus.brown.tagged_words('ca01', tagset='universal'))\n",
    "finder.nbest(bigram_measures.pmi, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
